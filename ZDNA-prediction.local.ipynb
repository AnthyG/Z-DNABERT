{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeAG1NZ5cLSz"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mitiau/DNABERT-Z/blob/main/ZDNA-prediction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f59Ujuujn___"
   },
   "source": [
    "# Install dependencies and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "apiUcTpNTnlU",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nix/store/kxkdrxvc3da2dpsgikn8s2ml97h88m46-bash-interactive-5.2-p15/bin/bash: line 1: pip3: command not found\n",
      "/nix/store/kxkdrxvc3da2dpsgikn8s2ml97h88m46-bash-interactive-5.2-p15/bin/bash: line 1: pip3: command not found\n",
      "/nix/store/kxkdrxvc3da2dpsgikn8s2ml97h88m46-bash-interactive-5.2-p15/bin/bash: line 1: pip3: command not found\n",
      "/nix/store/kxkdrxvc3da2dpsgikn8s2ml97h88m46-bash-interactive-5.2-p15/bin/bash: line 1: pip3: command not found\n",
      "/nix/store/kxkdrxvc3da2dpsgikn8s2ml97h88m46-bash-interactive-5.2-p15/bin/bash: line 1: pip3: command not found\n",
      "/nix/store/kxkdrxvc3da2dpsgikn8s2ml97h88m46-bash-interactive-5.2-p15/bin/bash: line 1: pip3: command not found\n",
      "/nix/store/kxkdrxvc3da2dpsgikn8s2ml97h88m46-bash-interactive-5.2-p15/bin/bash: line 1: pip3: command not found\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n",
    "!pip3 install biopython\n",
    "!pip3 install torch\n",
    "!pip3 install numpy\n",
    "!pip3 install scipy\n",
    "!pip3 install tqdm\n",
    "!pip3 install io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bsyfz4BrSxMN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from io import StringIO, BytesIO\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5I6iDSnocLS3"
   },
   "outputs": [],
   "source": [
    "def seq2kmer(seq, k):\n",
    "    kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n",
    "    return kmer\n",
    "\n",
    "def split_seq(seq, length = 512, pad = 16):\n",
    "    res = []\n",
    "    for st in range(0, len(seq), length - pad):\n",
    "        end = min(st+512, len(seq))\n",
    "        res.append(seq[st:end])\n",
    "    return res\n",
    "\n",
    "def stitch_np_seq(np_seqs, pad = 16):\n",
    "    res = np.array([])\n",
    "    for seq in np_seqs:\n",
    "        res = res[:-pad]\n",
    "        res = np.concatenate([res,seq])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HlrLFjVcLS4"
   },
   "source": [
    "# Select model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xYq4WVAtcLS4"
   },
   "outputs": [],
   "source": [
    "model_name = 'HG kouzine' #@param [\"HG chipseq\", \"HG kouzine\", \"MM chipseq\", \"MM kouzine\"]\n",
    "model_confidence_threshold = 0.5 #@param {type:\"number\"}\n",
    "minimum_sequence_length = 10 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'HG chipseq':\n",
    "    model_id = '1VAsp8I904y_J0PUhAQqpSlCn1IqfG0FB'\n",
    "    model_file_name = 'hg_chipseq.pytorch_model.bin'\n",
    "elif model_name == 'HG kouzine':\n",
    "    model_id = '1dAeAt5Gu2cadwDhbc7OnenUgDLHlUvkx'\n",
    "    model_file_name = 'hg_kouzine.pytorch_model.bin'\n",
    "elif model_name == 'MM curax':\n",
    "    model_id = '1W6GEgHNoitlB-xXJbLJ_jDW4BF35W1Sd'\n",
    "    model_file_name = 'mm_curax.pytorch_model.bin'\n",
    "elif model_name == 'MM kouzine':\n",
    "    model_id = '1dXpQFmheClKXIEoqcZ7kgCwx6hzVCv3H'\n",
    "    model_file_name = 'mm_kouzine.pytorch_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdown_wrapper(gdrive_id, file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        print(file_path, gdrive_id, 'already exists')\n",
    "        return\n",
    "    \n",
    "    # curl \"https://drive.google.com/uc?id=${id}&export=download&confirm=ABCD\" --verbose -L -o \n",
    "    gdrive_url = 'https://drive.google.com/uc?id={id}&export=download&confirm=ABCD'.format(id=gdrive_id)\n",
    "    \n",
    "    print(gdrive_url, file_path)\n",
    "    \n",
    "    !curl -L --progress-bar -o \"{file_path}\" \"{gdrive_url}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './6-new-12w-0'\n",
    "model_data_path = './pytorch_models'\n",
    "model_file_path = os.path.join(model_data_path, model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_files = [\n",
    "    ('10sF8Ywktd96HqAL0CwvlZZUUGj05CGk5', os.path.join(data_path, 'config.json')),\n",
    "    ('16bT7HDv71aRwyh3gBUbKwign1mtyLD2d', os.path.join(data_path, 'special_tokens_map.json')),\n",
    "    ('1EE9goZ2JRSD8UTx501q71lGCk-CK3kqG', os.path.join(data_path, 'tokenizer_config.json')),\n",
    "    ('1gZZdtAoDnDiLQqjQfGyuwt268Pe5sXW0', os.path.join(data_path, 'vocab.txt')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./6-new-12w-0’: File exists\n",
      "mkdir: cannot create directory ‘./pytorch_models’: File exists\n",
      "./pytorch_models/hg_kouzine.pytorch_model.bin 1dAeAt5Gu2cadwDhbc7OnenUgDLHlUvkx already exists\n",
      "./6-new-12w-0/config.json 10sF8Ywktd96HqAL0CwvlZZUUGj05CGk5 already exists\n",
      "./6-new-12w-0/special_tokens_map.json 16bT7HDv71aRwyh3gBUbKwign1mtyLD2d already exists\n",
      "./6-new-12w-0/tokenizer_config.json 1EE9goZ2JRSD8UTx501q71lGCk-CK3kqG already exists\n",
      "./6-new-12w-0/vocab.txt 1gZZdtAoDnDiLQqjQfGyuwt268Pe5sXW0 already exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir $data_path\n",
    "!mkdir $model_data_path\n",
    "\n",
    "gdown_wrapper(model_id, model_file_path)\n",
    "\n",
    "for meta_file in meta_files:\n",
    "    gdown_wrapper(meta_file[0], meta_file[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "c6h6-ttRcLS5"
   },
   "outputs": [],
   "source": [
    "!cp {model_file_path} {data_path}/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8hrJOXiscLS6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is  not  available\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(data_path)\n",
    "model = BertForTokenClassification.from_pretrained(data_path)\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print('cuda is ', '' if is_cuda_available else 'not ', 'available')\n",
    "if is_cuda_available:\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAp3NQyaupxE"
   },
   "source": [
    "# Upload fasta files for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "\n",
    "class Files:\n",
    "    def upload(_):\n",
    "        uploader = widgets.FileUpload(\n",
    "            multiple=True\n",
    "        )\n",
    "        display(uploader)\n",
    "        \n",
    "        return uploader\n",
    "\n",
    "files = Files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple files may be selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393f0c731d0b4e13a7dc9a7ae0989e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploader = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User uploaded file \"Tshz2.fa\" with length 1378 bytes\n",
      "User uploaded file \"input_example.fasta\" with length 2204 bytes\n",
      "User uploaded file \"Human Tshz2,promoter,exon 1.fa\" with length 2130 bytes\n",
      "User uploaded file \"example_toy.fasta\" with length 2629 bytes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# for older ipywidgets versions\n",
    "uploaded = {k: v['content'] for k, v in uploader.value.items()}\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "\"\"\"\n",
    "\n",
    "uploaded = {v['name']: v['content'] for v in uploader.value}\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrJ47H4bcLS8"
   },
   "source": [
    "# Predict and save raw outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir \"{output_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "_1qjq3i-VCEz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tshz2.fa\n",
      "Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  start     end\n",
      "\n",
      "Human Tshz2,promoter,exon 1.fa\n",
      "Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  start     end\n",
      "    1134     1186\n",
      "    1196     1211\n",
      "    1218     1249\n",
      "    1265     1281\n",
      "    1576     1612\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for key in uploaded.keys():\n",
    "    print(key)\n",
    "    out.append(key)\n",
    "    result_dict = {}\n",
    "    for seq_record in SeqIO.parse(StringIO(BytesIO(uploaded[key]).read().decode('UTF-8')), 'fasta'):\n",
    "        kmer_seq = seq2kmer(str(seq_record.seq).upper(), 6)\n",
    "        seq_pieces = split_seq(kmer_seq)\n",
    "        print(seq_record.name)\n",
    "        out.append(seq_record.name)\n",
    "        with torch.no_grad():\n",
    "            preds = []\n",
    "            for seq_piece in tqdm(seq_pieces):\n",
    "                input_ids = torch.LongTensor(tokenizer.encode(' '.join(seq_piece), add_special_tokens=False))\n",
    "                input_ids_unsqueezed = None\n",
    "                if is_cuda_available:\n",
    "                    input_ids_unsqueezed = input_ids.cuda().unsqueeze(0)\n",
    "                else:\n",
    "                    input_ids_unsqueezed = input_ids.cpu().unsqueeze(0)\n",
    "                outputs = torch.softmax(model(input_ids_unsqueezed)[-1],axis = -1)[0,:,1]\n",
    "                preds.append(outputs.cpu().numpy())\n",
    "        result_dict[seq_record.name] = stitch_np_seq(preds)\n",
    "\n",
    "\n",
    "\n",
    "        labeled, max_label = scipy.ndimage.label(result_dict[seq_record.name]>model_confidence_threshold)\n",
    "        print('  start     end')\n",
    "        out.append('  start     end')\n",
    "        for label in range(1, max_label+1):\n",
    "            candidate = np.where(labeled == label)[0]\n",
    "            candidate_length = candidate.shape[0]\n",
    "            if candidate_length>minimum_sequence_length:\n",
    "                print('{:8}'.format(candidate[0]), '{:8}'.format(candidate[-1]))\n",
    "                out.append('{:8}'.format(candidate[0]) + '{:8}'.format(candidate[-1]))\n",
    "\n",
    "    with open(os.path.join(output_path, key + '.preds.pkl'),\"wb\") as fh:\n",
    "      pickle.dump(result_dict, fh)\n",
    "    print()\n",
    "\n",
    "with open(os.path.join(output_path, 'text_predictions.txt'),\"w\") as fh:\n",
    "    for item in out:\n",
    "        fh.write(\"%s\\n\" % item)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ZDNA prediction",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

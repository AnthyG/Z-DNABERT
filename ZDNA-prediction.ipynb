{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mitiau/DNABERT-Z/blob/main/ZDNA-prediction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f59Ujuujn___"
   },
   "source": [
    "# Install dependecies and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apiUcTpNTnlU",
    "outputId": "d7491c10-dae0-4701-844d-1c76d0353a04"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bsyfz4BrSxMN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from io import StringIO, BytesIO\n",
    "from google.colab import drive, files\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2kmer(seq, k):\n",
    "    kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n",
    "    return kmer\n",
    "\n",
    "def split_seq(seq, length = 512, pad = 16):\n",
    "    res = []\n",
    "    for st in range(0, len(seq), length - pad):\n",
    "        end = min(st+512, len(seq))\n",
    "        res.append(seq[st:end])\n",
    "    return res\n",
    "        \n",
    "def stitch_np_seq(np_seqs, pad = 16):\n",
    "    res = np.array([])\n",
    "    for seq in np_seqs:\n",
    "        res = res[:-pad]\n",
    "        res = np.concatenate([res,seq])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'HG kouzine' #@param [\"HG chipseq\", \"HG kouzine\", \"MM chipseq\", \"MM kouzine\"]\n",
    "model_confidence_threshold = 0.5 #@param {type:\"number\"}\n",
    "minimum_sequence_length = 10 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'HG chipseq':\n",
    "    model_id = '1VAsp8I904y_J0PUhAQqpSlCn1IqfG0FB'\n",
    "elif model == 'HG kouzine':\n",
    "    model_id = '1dAeAt5Gu2cadwDhbc7OnenUgDLHlUvkx'\n",
    "elif model == 'MM curax':\n",
    "    model_id = '1W6GEgHNoitlB-xXJbLJ_jDW4BF35W1Sd'\n",
    "elif model == 'MM kouzine':\n",
    "    model_id = '1dXpQFmheClKXIEoqcZ7kgCwx6hzVCv3H'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown $model_id\n",
    "!gdown 10sF8Ywktd96HqAL0CwvlZZUUGj05CGk5\n",
    "!gdown 16bT7HDv71aRwyh3gBUbKwign1mtyLD2d\n",
    "!gdown 1EE9goZ2JRSD8UTx501q71lGCk-CK3kqG\n",
    "!gdown 1gZZdtAoDnDiLQqjQfGyuwt268Pe5sXW0 \n",
    "    \n",
    "\n",
    "!mkdir 6-new-12w-0\n",
    "!mv pytorch_model.bin 6-new-12w-0/\n",
    "!mv config.json 6-new-12w-0/\n",
    "!mv special_tokens_map.json 6-new-12w-0/\n",
    "!mv tokenizer_config.json 6-new-12w-0/\n",
    "!mv vocab.txt 6-new-12w-0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('6-new-12w-0/')\n",
    "model = BertForTokenClassification.from_pretrained('6-new-12w-0/')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAp3NQyaupxE"
   },
   "source": [
    "# Upload fasta files for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urrTMPfMUrbP"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and save raw outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1qjq3i-VCEz"
   },
   "outputs": [],
   "source": [
    "for key in uploaded.keys():\n",
    "    print(key)\n",
    "    result_dict = {}\n",
    "    for seq_record in SeqIO.parse(StringIO(BytesIO(uploaded[key]).read().decode('UTF-8')), 'fasta'):\n",
    "        kmer_seq = seq2kmer(str(seq_record.seq).upper(), 6)\n",
    "        seq_pieces = split_seq(kmer_seq)\n",
    "        print(seq_record.name)\n",
    "        with torch.no_grad():\n",
    "            preds = []\n",
    "            for seq_piece in tqdm(seq_pieces):\n",
    "                input_ids = torch.LongTensor(tokenizer.encode(' '.join(seq_piece), add_special_tokens=False))\n",
    "                outputs = torch.softmax(model(input_ids.cuda().unsqueeze(0))[-1],axis = -1)[0,:,1]\n",
    "                preds.append(outputs.cpu().numpy())\n",
    "        result_dict[seq_record.name] = stitch_np_seq(preds)\n",
    "    \n",
    "   \n",
    "    \n",
    "        labeled, max_label = scipy.ndimage.label(result_dict[seq_record.name]>model_confidence_threshold)\n",
    "        print('  start     end')\n",
    "        for label in range(1, max_label+1):\n",
    "            candidate = np.where(labeled == label)[0]\n",
    "            candidate_length = candidate.shape[0]\n",
    "            if candidate_length>minimum_sequence_length:\n",
    "                print('{:8}'.format(candidate[0]), '{:8}'.format(candidate[-1]))\n",
    "    \n",
    "    with open(key + '.preds.pkl',\"wb\") as fh:\n",
    "        pickle.dump(result_dict, fh)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download raw prediction files in numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4by6H7tRdcQO"
   },
   "outputs": [],
   "source": [
    "\n",
    "for key in uploaded.keys():\n",
    "    files.download(key + '.preds.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "ZDNA prediction",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
